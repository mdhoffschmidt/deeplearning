{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe word embeddings were due to Jeffrey Pennington, Richard Socher, and Christopher D. Manning. \n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding:\n",
    "    \"\"\"Class that handles word embeddings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.words = []\n",
    "        self.word_to_vec = {}\n",
    "        self.matrix = None\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "        \n",
    "    def load_glove(self, filepath, filename):\n",
    "        \"\"\"Load the representation.\n",
    "        \n",
    "        :param filepath: path to the file.\n",
    "        :type filepath: str.\n",
    "        :param filename: name of the file.\n",
    "        :type filename: str.\n",
    "        \"\"\"\n",
    "        self.words = []\n",
    "        self.matrix = []\n",
    "        self.word_to_vec = {}\n",
    "        \n",
    "        f = open(os.path.join(filepath, filename))\n",
    "        \n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coef = np.asarray(values[1:], dtype=\"float32\")\n",
    "            self.word_to_vec[word] = coef\n",
    "            self.words.append(word)\n",
    "            self.matrix.append(coef)\n",
    "        f.close()\n",
    "        self.matrix = np.array(self.matrix)\n",
    "        return\n",
    "\n",
    "    def cosine_similarity(self, u, v):\n",
    "        \"\"\"Mesure the cosine similarity between two arrays.\n",
    "        \n",
    "        :return: the cosine similarity.\n",
    "        :rtype: float.        \n",
    "        \"\"\"\n",
    "        norm_u = np.sqrt(np.sum(u * u))\n",
    "        norm_v = np.sqrt(np.sum(v * v))\n",
    "        return np.sum(u * v) / ( norm_u * norm_v )\n",
    "\n",
    "    def similar(self, word_a, word_b):\n",
    "        \"\"\"Mesure the similarity between word a and b.\n",
    "        \n",
    "        :param word_a: the first word.\n",
    "        :type word_a: str.\n",
    "        :param word_b: the second word.\n",
    "        :type word_b: str.\n",
    "        \n",
    "        :return: the cosine similarity.\n",
    "        :rtype: float.\n",
    "        \"\"\"\n",
    "        a = self.word_to_vec[word_a.lower()]\n",
    "        b = self.word_to_vec[word_b.lower()]\n",
    "        return self.cosine_similarity(a, b)\n",
    "    \n",
    "    def analogy(self, word_a, word_b, word_c):\n",
    "        \"\"\"Performs the word analogy.\n",
    "        \n",
    "        :param word_a: the first word.\n",
    "        :type word_a: str.\n",
    "        :param word_b: the second word.\n",
    "        :type word_b: str.\n",
    "        :param word_c: the third word.\n",
    "        :type word_c: str.          \n",
    "        \"\"\"\n",
    "        a = self.word_to_vec[word_a.lower()]\n",
    "        b = self.word_to_vec[word_b.lower()]\n",
    "        c = self.word_to_vec[word_c.lower()]\n",
    "        \n",
    "        max_sim = -1.0\n",
    "        best_word = None        \n",
    "        \n",
    "        for w, x in self.word_to_vec.items():\n",
    "            if w in [word_a, word_b, word_c]:\n",
    "                pass\n",
    "            else:\n",
    "                sim = self.cosine_similarity(a - b, c - x)\n",
    "                if sim > max_sim:\n",
    "                    max_sim = sim\n",
    "                    best_word = w \n",
    "                    \n",
    "        return best_word\n",
    "    \n",
    "    def neighbor(self, word, k=1):\n",
    "        \"\"\"Performs the task of finding the k nearest neighbors to the word.\n",
    "        \n",
    "        :param word: the reference word.\n",
    "        :type word: str.\n",
    "        :param k: the number of neighbors to find.\n",
    "        :type k: int.\n",
    "        \n",
    "        :return: the k-nearest neighbors.\n",
    "        :rtype: list<str>.\n",
    "        \"\"\"\n",
    "        if isinstance(word, str):\n",
    "            vec = self.word_to_vec[word.lower()]\n",
    "        else:\n",
    "            vec = word\n",
    "    \n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, algorithm=\"ball_tree\").fit(self.matrix)\n",
    "        distances, indices = nbrs.kneighbors(vec.reshape(1,-1))\n",
    "\n",
    "        best_words = []\n",
    "        for i in indices.tolist()[0][1:]:\n",
    "            best_words.append(self.words[i])\n",
    "\n",
    "        return best_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test\n",
    "\n",
    "We define here the parameters required to run the test. \n",
    "Feel free to change the embedding dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be changed to 50, 100 or 200.\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words = 400000\n"
     ]
    }
   ],
   "source": [
    "# File details.\n",
    "GLOVE_DIR = \"dataset/glove\"\n",
    "GLOVE_FILE = \"glove.6B.{}d.txt\".format(EMBEDDING_DIM)\n",
    "\n",
    "# Load the word embedding.\n",
    "glove = WordEmbedding()\n",
    "glove.load_glove(GLOVE_DIR, GLOVE_FILE)\n",
    "\n",
    "# Display.\n",
    "print(\"Total number of words = {}\".format(len(glove)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Similarity.\n",
    "\n",
    "You can mesure the similary between two words. For instance man and boy will be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man & boy = 0.8564431071281433\n",
      "woman & girl = 0.906528115272522\n",
      "London & zurich = 0.5148636102676392\n",
      "table & bird = 0.2420566827058792\n",
      "sister & brother = 0.7250392436981201\n"
     ]
    }
   ],
   "source": [
    "# Define the test to run.\n",
    "tests =[\n",
    "    [\"man\", \"boy\"],\n",
    "    [\"woman\", \"girl\"],\n",
    "    [\"London\", \"zurich\"],\n",
    "    [\"table\", \"bird\"],\n",
    "    [\"sister\", \"brother\"]\n",
    "]\n",
    "\n",
    "# Perform the tests.\n",
    "for test in tests:\n",
    "    sim = glove.similar(test[0], test[1])\n",
    "    print(\"{} & {} = {}\".format(test[0], test[1], sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Analogy\n",
    "\n",
    "You can also evaluate the analogy between woman to queen, man to ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small -> smaller & large -> larger\n",
      "france -> paris & sweden -> stockholm\n",
      "india -> delhi & japan -> tokyo\n",
      "man -> woman & boy -> girl\n"
     ]
    }
   ],
   "source": [
    "# Define the test to run.\n",
    "tests =[\n",
    "    [\"small\", \"smaller\", \"large\"],\n",
    "    [\"france\", \"paris\", \"sweden\"],    \n",
    "    [\"india\", \"delhi\", \"japan\"],\n",
    "    [\"man\", \"woman\", \"boy\"],\n",
    "]\n",
    "\n",
    "# Perform the tests.\n",
    "for test in tests:\n",
    "    a, b, c = test\n",
    "    d = glove.analogy(a, b, c)\n",
    "    print(\"{} -> {} & {} -> {}\".format(a, b, c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'vec' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-004f2d54dfe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Obtain the nearest neighbors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Display the nearest neighbors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-499c33563296>\u001b[0m in \u001b[0;36mneighbor\u001b[0;34m(self, word, k)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \"\"\"\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mnbrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ball_tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'vec' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Obtain the nearest neighbors.\n",
    "words = glove.neighbor(\"beer\", k=10)\n",
    "\n",
    "# Display the nearest neighbors.\n",
    "for w in words:\n",
    "    print(\"{}\".format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
