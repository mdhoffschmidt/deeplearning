{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Vectors for Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GloVe word embeddings were due to Jeffrey Pennington, Richard Socher, and Christopher D. Manning. \n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor.\n",
    "        \"\"\"\n",
    "        self.words = []\n",
    "        self.word_to_vec = {}\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "    \n",
    "    def load_glove(self, filepath, filename):\n",
    "        \"\"\"Load the representation.\n",
    "        \n",
    "        :param filepath: path to the file.\n",
    "        :type filepath: str.\n",
    "        :param filename: name of the file.\n",
    "        :type filename: str.\n",
    "        \"\"\"\n",
    "        self.word_to_vec = {}\n",
    "        f = open(os.path.join(filepath, filename))\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coef = np.asarray(values[1:], dtype=\"float32\")\n",
    "            self.word_to_vec[word] = coef\n",
    "        f.close()\n",
    "        self.words = list(self.word_to_vec.keys())\n",
    "        return\n",
    "\n",
    "    def cosine_similarity(self, u, v):\n",
    "        \"\"\"Mesure the cosine similarity between two arrays.\n",
    "        \"\"\"\n",
    "        norm_u = np.sqrt(np.sum(u * u))\n",
    "        norm_v = np.sqrt(np.sum(v * v))\n",
    "        return np.sum(u * v) / ( norm_u * norm_v )\n",
    "\n",
    "    def similar(self, word_a, word_b):\n",
    "        \"\"\"Mesure the similarity between word a and b.\n",
    "        \"\"\"\n",
    "        a = self.word_to_vec[word_a.lower()]\n",
    "        b = self.word_to_vec[word_b.lower()]\n",
    "        return self.cosine_similarity(a, b)\n",
    "    \n",
    "    def analogy(self, word_a, word_b, word_c):\n",
    "        \"\"\"Performs the word analogy task as explained above: a is to b as c is to ____.\n",
    "        \"\"\"\n",
    "        a = self.word_to_vec[word_a.lower()]\n",
    "        b = self.word_to_vec[word_b.lower()]\n",
    "        c = self.word_to_vec[word_c.lower()]\n",
    "        \n",
    "        max_sim = -1.0\n",
    "        best_word = None        \n",
    "        \n",
    "        for w, x in self.word_to_vec.items():\n",
    "            if w in [word_a, word_b, word_c]:\n",
    "                pass\n",
    "            else:\n",
    "                sim = self.cosine_similarity(a - b, c - x)\n",
    "                if sim > max_sim:\n",
    "                    max_sim = sim\n",
    "                    best_word = w \n",
    "                    \n",
    "        return best_word\n",
    "    \n",
    "    def neighbor(self, word, k=1):\n",
    "        \"\"\"Performs the task of finding the k nearest neighbors to the word.\n",
    "        \"\"\"\n",
    "        vec = self.word_to_vec[word.lower()]\n",
    "        \n",
    "        max_sims = []\n",
    "        best_words = []\n",
    "        for i in range(k):\n",
    "            max_sims.append(-1.1)\n",
    "            best_words.append(None)\n",
    "        \n",
    "        for w, x in self.word_to_vec.items():\n",
    "            if w in [word]:\n",
    "                pass\n",
    "            else:\n",
    "                sim = self.cosine_similarity(vec, x)\n",
    "                \n",
    "                if sim >= min(max_sims):\n",
    "                    for i in range(k):\n",
    "                        if sim > max_sims[i]:\n",
    "                            max_sims[i] = sim\n",
    "                            best_words[i] = w\n",
    "                            break\n",
    "\n",
    "        return best_words, max_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test\n",
    "\n",
    "We define here the parameters required to run the test. \n",
    "Feel free to change the embedding dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be changed to 50, 100 or 200.\n",
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words = 400000\n"
     ]
    }
   ],
   "source": [
    "# File details.\n",
    "GLOVE_DIR = \"dataset/glove\"\n",
    "GLOVE_FILE = \"glove.6B.{}d.txt\".format(EMBEDDING_DIM)\n",
    "\n",
    "# Load the word embedding.\n",
    "word2vec = WordEmbedding()\n",
    "word2vec.load_glove(GLOVE_DIR, GLOVE_FILE)\n",
    "\n",
    "# Display.\n",
    "print(\"Total number of words = {}\".format(len(word2vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Similarity.\n",
    "\n",
    "You can mesure the similary between two words. For instance man and boy will be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man & boy = 0.8564431071281433\n",
      "woman & girl = 0.906528115272522\n",
      "London & zurich = 0.5148636102676392\n",
      "table & bird = 0.2420566827058792\n",
      "sister & brother = 0.7250392436981201\n"
     ]
    }
   ],
   "source": [
    "# Define the test to run.\n",
    "tests =[\n",
    "    [\"man\", \"boy\"],\n",
    "    [\"woman\", \"girl\"],\n",
    "    [\"London\", \"zurich\"],\n",
    "    [\"table\", \"bird\"],\n",
    "    [\"sister\", \"brother\"]\n",
    "]\n",
    "\n",
    "# Perform the tests.\n",
    "for test in tests:\n",
    "    sim = word2vec.similar(test[0], test[1])\n",
    "    print(\"{} & {} = {}\".format(test[0], test[1], sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Analogy\n",
    "\n",
    "You can also evaluate the analogy between woman to queen, man to ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small -> smaller & large -> larger\n",
      "france -> paris & sweden -> stockholm\n",
      "india -> delhi & japan -> tokyo\n",
      "man -> woman & boy -> girl\n"
     ]
    }
   ],
   "source": [
    "# Define the test to run.\n",
    "tests =[\n",
    "    [\"small\", \"smaller\", \"large\"],\n",
    "    [\"france\", \"paris\", \"sweden\"],    \n",
    "    [\"india\", \"delhi\", \"japan\"],\n",
    "    [\"man\", \"woman\", \"boy\"],\n",
    "]\n",
    "\n",
    "# Perform the tests.\n",
    "for test in tests:\n",
    "    a, b, c = test\n",
    "    d = word2vec.analogy(a, b, c)\n",
    "    print(\"{} -> {} & {} -> {}\".format(a, b, c, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tables ................. = 0.8177436590194702\n",
      "sit .................... = 0.7571902871131897\n",
      "hold ................... = 0.7306693196296692\n",
      "bottom ................. = 0.7166719436645508\n",
      "sitting ................ = 0.6948686838150024\n",
      "pool ................... = 0.6913972496986389\n",
      "wrap ................... = 0.6869691610336304\n",
      "draw ................... = 0.6701829433441162\n",
      "standing ............... = 0.6688733696937561\n",
      "placing ................ = 0.6672315001487732\n"
     ]
    }
   ],
   "source": [
    "# Obtain the nearest neighbors.\n",
    "words, cos_sim = word2vec.neighbor(\"table\", k=10)\n",
    "\n",
    "# Display the nearest neighbors.\n",
    "for w, sim in zip(words, cos_sim):\n",
    "    dotes = \".\" * ( 23 - len(w) )\n",
    "    print(\"{} {} = {}\".format(w, dotes, sim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
